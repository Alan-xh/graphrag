# 数据流索引

## GraphRAG 知识模型

知识模型是符合我们数据模型定义的数据输出规范。您可以在 GraphRAG 仓库中的 `python/graphrag/graphrag/model` 文件夹中找到这些定义。以下是提供的实体类型。这些字段表示默认情况下进行文本嵌入的字段。

- `文档（Document）` - 系统输入的文档。这些文档要么表示 CSV 中的单行数据，要么表示单个 .txt 文件。
- `文本单元（TextUnit）` - 用于分析的文本片段。这些片段的大小、它们的交叠以及是否遵循任何数据边界都可以在下方配置。一个常见的用例是将 `CHUNK_BY_COLUMNS` 设置为 `id`，以便文档与文本单元之间形成一对多的关系，而不是多对多的关系。
- `实体（Entity）` - 从文本单元中提取的实体。这些实体代表人物、地点、事件或其他您提供的实体模型。
- `关系（Relationship）` - 两个实体之间的关系。
- `协变量（Covariate）` - 提取的声明信息，包含关于实体的可能受时间限制的陈述。
- `社区（Community）` - 在构建实体和关系图后，我们对其进行层次社区检测，以创建聚类结构。
- `社区报告（Community Report）` - 每个社区的内容被总结成一份生成的报告，便于人类阅读和下游搜索。

## 默认配置工作流程

让我们来看看默认配置工作流程如何将文本文档转换为 _GraphRAG 知识模型_。本页提供了该过程主要步骤的总体概述。要完全配置此工作流程，请查看 [配置文档](../config/overview.md)。

```mermaid
---
title: 数据流概览
---
flowchart TB
    subgraph phase1[阶段 1：构建文本单元]
    documents[文档] --> chunk[分块]
    chunk --> textUnits[文本单元]
    end
    subgraph phase2[阶段 2：图提取]
    textUnits --> graph_extract[实体与关系提取]
    graph_extract --> graph_summarize[实体与关系总结]
    graph_summarize --> claim_extraction[声明提取]
    claim_extraction --> graph_outputs[图表]
    end
    subgraph phase3[阶段 3：图增强]
    graph_outputs --> community_detect[社区检测]
    community_detect --> community_outputs[社区表]
    end
    subgraph phase4[阶段 4：社区总结]
    community_outputs --> summarized_communities[社区总结]
    summarized_communities --> community_report_outputs[社区报告表]
    end
    subgraph phase5[阶段 5：文档处理]
    documents --> link_to_text_units[链接到文本单元]
    textUnits --> link_to_text_units
    link_to_text_units --> document_outputs[文档表]
    end
    subgraph phase6[阶段 6：网络可视化]
    graph_outputs --> graph_embed[图嵌入]
    graph_embed --> umap_entities[Umap 实体]
    umap_entities --> combine_nodes[最终实体]
    end
    subgraph phase7[阶段 7：文本嵌入]
    textUnits --> text_embed[文本嵌入]
    graph_outputs --> description_embed[描述嵌入]
    community_report_outputs --> content_embed[内容嵌入]
    end
```

## 阶段 1：构建文本单元

默认配置工作流程的第一阶段是将输入文档转换为 _文本单元_。_文本单元_ 是用于图提取技术的文本片段。它们还被提取的知识项用作源引用，以支持概念追溯到原始源文本的路径和出处。

分块大小（以 token 计数）是用户可配置的。默认情况下设置为 300 个 token，尽管我们使用单一“收集”步骤（glean step）处理 1200 个 token 的分块取得了积极的经验。较大的分块会导致输出保真度较低，参考文本的意义减少；然而，使用较大的分块可以显著加快处理速度。

分组配置也是用户可配置的。默认情况下，我们将分块与文档边界对齐，这意味着文档与文本单元之间存在严格的一对多关系。在极少数情况下，这可以转变为多对多关系。当文档非常短小，且需要多个文档组成一个有意义的分析单元时（例如推文或聊天记录），这种方式非常有用。

```mermaid
---
title: 文档转换为文本分块
---
flowchart LR
    doc1[文档 1] --> tu1[文本单元 1]
    doc1 --> tu2[文本单元 2]
    doc2[文档 2] --> tu3[文本单元 3]
    doc2 --> tu4[文本单元 4]
```

## 阶段 2：图提取

在此阶段，我们分析每个文本单元，提取图原语：_实体_、_关系_ 和 _声明_。实体和关系在我们的 _entity_extract_ 动词中同时提取，声明则在 _claim_extract_ 动词中提取。结果随后被合并并传递到管道的后续阶段。

```mermaid
---
title: 图提取
---
flowchart LR
    tu[文本单元] --> ge[图提取] --> gs[图总结]
    tu --> ce[声明提取]
```

### 实体与关系提取

在图提取的第一步中，我们处理每个文本单元，以使用大语言模型（LLM）从原始文本中提取实体和关系。此步骤的输出是每个文本单元的子图，包含带有 _标题_、_类型_ 和 _描述_ 的 **实体** 列表，以及带有 _源_、_目标_ 和 _描述_ 的 **关系** 列表。

这些子图被合并在一起——任何具有相同 _标题_ 和 _类型_ 的实体通过创建其描述的数组进行合并。同样，任何具有相同 _源_ 和 _目标_ 的关系通过创建其描述的数组进行合并。

### 实体与关系总结

现在我们有了一个包含实体和关系的图，每个实体和关系都带有一系列描述，我们可以将这些描述列表总结为每个实体和关系的单一描述。这是通过要求大语言模型提供一个简短的总结来完成的，该总结涵盖了每个描述中的所有独特信息。这使得我们的所有实体和关系都具有一个简洁的描述。

### 声明提取（可选）

最后，作为一个独立的工作流程，我们从源文本单元中提取声明。这些声明表示具有评估状态和时间限制的正面事实陈述。这些声明作为主要产物导出，称为 **协变量**。

注意：声明提取是 _可选_ 的，默认情况下关闭。这是因为声明提取通常需要调整提示词才能发挥作用。

## 阶段 3：图增强

现在我们有了一个可用的实体和关系图，我们希望了解其社区结构。这为我们提供了理解图拓扑结构的明确方式。

```mermaid
---
title: 图增强
---
flowchart LR
    cd[Leiden 层次社区检测] --> ag[图表]
```

### 社区检测

在此步骤中，我们使用层次 Leiden 算法生成实体社区的层次结构。此方法将对我们的图进行递归社区聚类，直到达到社区大小阈值。这使我们能够了解图的社区结构，并提供在不同粒度级别上导航和总结图的方法。

### 图表

一旦图增强步骤完成，最终的 **实体**、**关系** 和 **社区** 表将被导出。

## 阶段 4：社区总结

```mermaid
---
title: 社区总结
---
flowchart LR
    sc[生成社区报告] --> ss[总结社区报告] --> co[社区报告表]
```

此时，我们有了一个功能完整的实体和关系图以及实体的社区层次结构。

现在我们希望基于社区数据生成每个社区的报告。这为我们在图的多个粒度级别上提供了高层次的理解。例如，如果社区 A 是顶级社区，我们将获得关于整个图的报告。如果社区是较低级别的，我们将获得关于本地集群的报告。

### 生成社区报告

在此步骤中，我们使用大语言模型为每个社区生成摘要。这使我们能够了解每个社区中包含的独特信息，并提供从高层次或低层次视角对图的范围理解。这些报告包含执行概述，并引用社区子结构中的关键实体、关系和声明。

### 总结社区报告

在此步骤中，每个 _社区报告_ 随后通过大语言模型进行总结，以供简要使用。

### 社区报告表

此时，进行一些簿记工作，并导出 **社区报告** 表。

## 阶段 5：文档处理

在此工作流程阶段，我们为知识模型创建 _文档_ 表。

```mermaid
---
title: 文档处理
---
flowchart LR
    aug[增强] --> dp[链接到文本单元] --> dg[文档表]
```

### 使用列增强（仅限 CSV）

如果工作流程处理的是 CSV 数据，您可以配置工作流程以向文档输出添加额外的字段。这些字段应存在于传入的 CSV 表中。有关配置的详细信息，请参阅 [配置文档](../config/overview.md)。

### 链接到文本单元

在此步骤中，我们将每个文档链接到第一阶段创建的文本单元。这使我们能够了解哪些文档与哪些文本单元相关，反之亦然。

### 文档表

此时，我们可以将 **文档** 表导出到知识模型中。

## 阶段 6：网络可视化（可选）

在此工作流程阶段，我们执行一些步骤以支持现有图中高维向量空间的网络可视化。此时有两个逻辑图在起作用：_实体-关系_ 图和 _文档_ 图。

```mermaid
---
title: 网络可视化工作流程
---
flowchart LR
    ag[图表] --> ge[Node2Vec 图嵌入] --> ne[Umap 实体] --> ng[实体表]
```

### 图嵌入

在此步骤中，我们使用 Node2Vec 算法生成图的向量表示。这使我们能够了解图的隐式结构，并提供一个额外的向量空间，以便在查询阶段搜索相关概念。

### 降维

对于每个逻辑图，我们执行 UMAP 降维以生成图的二维表示。这使我们能够在二维空间中可视化图，并了解图中节点之间的关系。UMAP 嵌入被降维为二维的 x/y 坐标。

## 阶段 7：文本嵌入

对于所有需要下游向量搜索的产物，我们在最后一步生成文本嵌入。这些嵌入直接写入配置的向量存储中。默认情况下，我们嵌入实体描述、文本单元文本和社区报告文本。

```mermaid
---
title: 文本嵌入工作流程
---
flowchart LR
    textUnits[文本单元] --> text_embed[文本嵌入]
    graph_outputs[图表] --> description_embed[描述嵌入]
    community_report_outputs[社区报告] --> content_embed[内容嵌入]
```